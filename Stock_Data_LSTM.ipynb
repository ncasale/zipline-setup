{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- may want to consider rebalancing signals to be evenly distributed. For aapl_extended, 27% are 0, 35% are 1, and 38% are 2\n",
    "- -we are having a vanishing gradient issue, since all of our values are very small decimals. Should scale these somehow.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>50ma</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cal_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-03-18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.022848</td>\n",
       "      <td>-0.324816</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>-0.007091</td>\n",
       "      <td>-0.422166</td>\n",
       "      <td>-0.068874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006699</td>\n",
       "      <td>-0.002598</td>\n",
       "      <td>-0.021084</td>\n",
       "      <td>-0.014165</td>\n",
       "      <td>0.346232</td>\n",
       "      <td>-0.036981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.028100</td>\n",
       "      <td>-0.023074</td>\n",
       "      <td>-0.053077</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>0.924736</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-03-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066206</td>\n",
       "      <td>0.072047</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      open      high       low  adj_close    volume      50ma  \\\n",
       "cal_date                                                                        \n",
       "1998-03-18   1.0 -0.018868  0.009367  0.005025   0.022848 -0.324816 -0.015385   \n",
       "1998-03-19   1.0  0.033462  0.000000  0.021538  -0.007091 -0.422166 -0.068874   \n",
       "1998-03-20   1.0 -0.006699 -0.002598 -0.021084  -0.014165  0.346232 -0.036981   \n",
       "1998-03-23   3.0 -0.028100 -0.023074 -0.053077  -0.009539  0.924736 -0.016700   \n",
       "1998-03-24   1.0  0.016577  0.066667  0.066206   0.072047  0.629787 -0.009956   \n",
       "\n",
       "           label  \n",
       "cal_date          \n",
       "1998-03-18     1  \n",
       "1998-03-19     1  \n",
       "1998-03-20     2  \n",
       "1998-03-23     2  \n",
       "1998-03-24     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cleaned_data(ticker, pred_window):\n",
    "    # Get stock data from csv\n",
    "    stock_data = pd.read_csv('./data/{}_extended.csv'.format(ticker), index_col=0).rename_axis('cal_date').reset_index()\n",
    "    stock_data = stock_data.set_index('cal_date')\n",
    "    \n",
    "    # Generate new columns\n",
    "    stock_data['50ma'] = pd.Series.rolling(stock_data['volume'],50, min_periods=50).mean().round()\n",
    "    stock_data['label'] = stock_data['adj_close'].shift(periods=-pred_window)\n",
    "    stock_data['label'] = stock_data['label'] - stock_data['adj_close']\n",
    "    stock_data['label'] = pd.Series(stock_data['label']/stock_data['adj_close']*100).astype(float)\n",
    "    stock_data['label'] = pd.cut(stock_data['label'], [np.NINF,-2,2,np.inf], labels= [0, 1, 2])\n",
    "    \n",
    "    # Format columns as differences\n",
    "    # NOTE: Date is formatted as the difference in days to keep value ranges lower.\n",
    "    for column in stock_data:\n",
    "        if column not in ['date', 'label']:\n",
    "            stock_data[column] = stock_data[column].pct_change()\n",
    "            \n",
    "    # Drop all cols that contain NAs\n",
    "    stock_data.dropna(inplace = True)\n",
    "    \n",
    "    # Refactor date column to be days since last datatpoint and drop NA's again\n",
    "    stock_data['date'] = stock_data.index\n",
    "    stock_data['date'] = stock_data['date'].apply(lambda x: time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%d\").timetuple()), convert_dtype=True)\n",
    "    stock_data['date'] = stock_data['date'].diff()/86400\n",
    "    stock_data['date'] = stock_data['date'].round()\n",
    "    \n",
    "    stock_data = stock_data.loc[:, ['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume', '50ma', 'label']]\n",
    "    stock_data.drop(labels='close', inplace = True, axis = 1)\n",
    "    stock_data.dropna(inplace = True)\n",
    "    return stock_data\n",
    "\n",
    "    \n",
    "ticker = 'aapl'\n",
    "pred_window = 5\n",
    "stock_data = get_cleaned_data(ticker, pred_window)\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open: 0.001029... 0.031274...\n",
      "high: 0.000915... 0.027450...\n",
      "low: 0.000980... 0.029448...\n",
      "adj_close: 0.001400... 0.026786...\n",
      "volume: 0.081624... 0.519295...\n",
      "50ma: 0.000500... 0.017036...\n"
     ]
    }
   ],
   "source": [
    "def analyze_distribution(series):\n",
    "    # return mean and std-dev of series\n",
    "    return np.mean(series), np.std(series)\n",
    "\n",
    "cols = ['open', 'high', 'low', 'adj_close', 'volume', '50ma']\n",
    "for col in cols:\n",
    "    mean, stddev = analyze_distribution(stock_data[col])\n",
    "    print(\"{}: {:.6f}... {:.6f}...\".format(col, mean, stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Pre-Standardization ------\n",
      "open: 0.001029... 0.031274...\n",
      "high: 0.000915... 0.027450...\n",
      "low: 0.000980... 0.029448...\n",
      "adj_close: 0.001400... 0.026786...\n",
      "volume: 0.081624... 0.519295...\n",
      "50ma: 0.000500... 0.017036...\n",
      "------ Post-Standardization ------\n",
      "open: 0.000000... 1.000000...\n",
      "high: -0.000000... 1.000000...\n",
      "low: -0.000000... 1.000000...\n",
      "adj_close: -0.000000... 1.000000...\n",
      "volume: 0.000000... 1.000000...\n",
      "50ma: 0.000000... 1.000000...\n"
     ]
    }
   ],
   "source": [
    "def standardize_series(series):\n",
    "    return (series - np.mean(series))/np.std(series)\n",
    "\n",
    "# Standardize the numeric columns of our dataset\n",
    "cols = ['open', 'high', 'low', 'adj_close', 'volume', '50ma']\n",
    "\n",
    "# Print out pre-standardized distribution metrics\n",
    "print('------ Pre-Standardization ------')\n",
    "for col in cols:\n",
    "    mean, stddev = analyze_distribution(stock_data[col])\n",
    "    print(\"{}: {:.6f}... {:.6f}...\".format(col, mean, stddev))\n",
    "\n",
    "# Standardize\n",
    "for col in cols:\n",
    "    stock_data[col] = standardize_series(stock_data[col])\n",
    "\n",
    "# Print out post-standardized distribution metrics\n",
    "print('------ Post-Standardization ------')\n",
    "for col in cols:\n",
    "    mean, stddev = analyze_distribution(stock_data[col])\n",
    "    print(\"{}: {:.6f}... {:.6f}...\".format(col, mean, stddev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5289,)\n",
      "(5289, 7)\n",
      "0.27661183588580074 0.3480809226696918 0.37530724144450744\n"
     ]
    }
   ],
   "source": [
    "# Get input data and labels\n",
    "signals = stock_data['label'].values\n",
    "daily_data = stock_data.drop(['label'], axis=1).values\n",
    "\n",
    "print(signals.shape)\n",
    "print(daily_data.shape)\n",
    "\n",
    "zero = [val for val in signals if val == 0]\n",
    "one = [val for val in signals if val == 1]\n",
    "two = [val for val in signals if val == 2]\n",
    "\n",
    "print(len(zero)/len(signals), len(one)/len(signals), len(two)/len(signals))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(daily_data, labels, input_length=7, sequence_length=10, batch_size=10):\n",
    "    # Get total number of days for which we have data -- only want full batches\n",
    "    days_per_batch = batch_size * sequence_length\n",
    "    total_days = (len(daily_data) // days_per_batch) * days_per_batch\n",
    "    \n",
    "    # Iterate through daily data, at intervals of batch_size X sequence_length\n",
    "    for ii in range(0, total_days, days_per_batch):\n",
    "        \n",
    "        # Get all days in this batch\n",
    "        batch_days = daily_data[ii: ii+days_per_batch]\n",
    "        \n",
    "        # Create the batch/label tensor of the right shape (seq_len x batch_size x input_features)\n",
    "        batch = torch.zeros((sequence_length, batch_size, input_length), dtype=torch.float64)\n",
    "        label_data = []\n",
    "        \n",
    "        # Fill out this batch/labels\n",
    "        for batch_num, jj in enumerate(range(0, len(batch_days), sequence_length)):\n",
    "            sequence_tensor = torch.tensor(batch_days[jj:jj+sequence_length])\n",
    "            batch[:, batch_num] = sequence_tensor\n",
    "            \n",
    "            # Only want labels for day at the end of sequence\n",
    "            label_data.append(labels[jj+sequence_length-1])\n",
    "            \n",
    "        # Fill out label tensor\n",
    "        label_tensor = torch.tensor(label_data)\n",
    "        \n",
    "        yield batch, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and validation sets -- will have testing data be first data\n",
    "# in dataset\n",
    "test_prop = 0.2\n",
    "test_end_idx = int(len(daily_data) * test_prop)\n",
    "\n",
    "# Create testing data\n",
    "test_features = daily_data[:test_end_idx]\n",
    "test_labels = signals[:test_end_idx]\n",
    "\n",
    "# Create training data\n",
    "train_features = daily_data[test_end_idx:]\n",
    "train_labels = signals[test_end_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 7]) tensor([[[ 3.0000e+00, -2.9058e-02, -3.2990e-02, -3.0069e-02, -1.6741e-02,\n",
      "          -3.5673e-01, -2.7282e-02],\n",
      "         [ 3.0000e+00, -1.2868e-02, -4.5579e-03,  1.9589e-02,  3.7944e-03,\n",
      "          -5.4672e-01,  1.1877e-02],\n",
      "         [ 3.0000e+00,  5.1975e-02,  1.3261e-02,  9.6080e-02,  2.1861e-02,\n",
      "          -2.3603e-01,  3.0620e-03],\n",
      "         [ 3.0000e+00, -1.1786e-02,  1.3722e-02, -5.3603e-03,  2.4849e-02,\n",
      "          -2.9750e-02,  6.5802e-03],\n",
      "         [ 3.0000e+00,  3.5673e-02,  3.3670e-03,  2.9412e-03, -3.7197e-02,\n",
      "          -1.7479e-01, -9.1146e-03],\n",
      "         [ 1.0000e+00, -2.3218e-02, -1.7195e-02, -1.2443e-02, -2.6609e-02,\n",
      "           7.3605e-02, -4.7008e-03],\n",
      "         [ 1.0000e+00,  4.1308e-02, -1.6129e-03,  4.7591e-02, -2.0262e-02,\n",
      "           5.0938e-01,  1.2798e-02],\n",
      "         [ 1.0000e+00,  1.0169e-02, -3.9500e-03, -1.1636e-02, -3.0093e-02,\n",
      "          -7.1960e-02,  8.8772e-03],\n",
      "         [ 1.0000e+00,  2.5552e-02,  2.7152e-02,  1.3222e-02,  2.7348e-02,\n",
      "           2.9051e-01,  6.3259e-03],\n",
      "         [ 1.0000e+00, -2.0675e-02,  3.6054e-02,  7.8740e-03,  5.3602e-02,\n",
      "           3.3343e-01,  5.7115e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -2.1804e-02, -1.7484e-02, -1.7715e-02, -5.6984e-03,\n",
      "           4.7940e-01,  1.0713e-02],\n",
      "         [ 1.0000e+00,  7.4488e-03, -6.4103e-03, -4.3580e-02, -4.7510e-02,\n",
      "           2.5910e-01,  1.0441e-02],\n",
      "         [ 1.0000e+00,  8.8933e-03, -1.9389e-03,  6.5491e-03, -1.8991e-02,\n",
      "           8.8569e-02,  6.0606e-03],\n",
      "         [ 1.0000e+00,  3.7567e-02, -2.8201e-03,  9.5808e-03, -7.4675e-03,\n",
      "          -3.0267e-01,  1.0718e-04],\n",
      "         [ 1.0000e+00, -3.8396e-02, -4.0268e-02, -1.2903e-02, -7.0922e-03,\n",
      "           3.7047e-01,  2.1540e-03],\n",
      "         [ 1.0000e+00, -2.1006e-02, -6.5610e-03, -1.2027e-02, -1.1988e-02,\n",
      "          -8.7624e-02, -3.9488e-03],\n",
      "         [ 1.0000e+00, -1.1129e-01, -1.2763e-01, -1.3742e-01, -1.2489e-01,\n",
      "           1.7206e+00,  5.6505e-02],\n",
      "         [ 1.0000e+00, -3.8255e-02,  5.9484e-03, -1.3158e-02,  5.0391e-02,\n",
      "           1.6763e-02,  7.5416e-03],\n",
      "         [ 1.0000e+00,  3.7037e-02, -5.8027e-03,  2.3352e-02, -1.1040e-02,\n",
      "          -1.2439e-01,  2.1664e-03],\n",
      "         [ 1.0000e+00,  6.1928e-02,  8.5358e-03,  1.9176e-02,  1.9659e-02,\n",
      "           2.2577e-01,  9.8562e-03]],\n",
      "\n",
      "        [[ 1.0000e+00, -2.1853e-03, -6.5104e-03,  7.6646e-03, -2.5860e-03,\n",
      "          -2.0338e-01,  1.0374e-03],\n",
      "         [ 1.0000e+00, -5.6839e-02, -4.3779e-02, -2.3028e-02, -1.8053e-02,\n",
      "           5.1280e-01,  2.2317e-02],\n",
      "         [ 1.0000e+00, -1.4936e-01, -1.4522e-01, -1.5516e-01, -1.5036e-01,\n",
      "           3.8377e+00,  9.9560e-02],\n",
      "         [ 1.0000e+00, -3.4483e-02, -2.2059e-02, -5.2195e-02, -3.4460e-02,\n",
      "           8.5574e-01, -3.2553e-03],\n",
      "         [ 1.0000e+00, -1.2918e-02,  3.0303e-02, -4.7534e-03,  3.5996e-02,\n",
      "          -3.4785e-01, -2.0699e-03],\n",
      "         [ 1.0000e+00, -2.5409e-02,  9.9064e-03, -1.6232e-02,  5.6531e-02,\n",
      "           8.0624e-01,  5.6195e-03],\n",
      "         [ 1.0000e+00, -3.9058e-02, -3.9506e-02, -2.8966e-02, -4.0949e-02,\n",
      "          -5.3972e-01,  1.7538e-02],\n",
      "         [ 1.0000e+00,  4.1870e-02, -1.7740e-02, -1.6842e-02, -5.5201e-02,\n",
      "           1.7895e-01, -2.5034e-03],\n",
      "         [ 1.0000e+00, -1.8831e-02,  0.0000e+00, -1.1409e-02, -3.0151e-02,\n",
      "          -2.6309e-01, -2.7580e-03],\n",
      "         [ 1.0000e+00, -2.1206e-02,  1.3021e-03,  2.9268e-02,  1.8008e-02,\n",
      "          -3.1824e-01,  2.9506e-04]],\n",
      "\n",
      "        [[ 1.0000e+00,  5.6943e-03,  1.4854e-02, -1.3870e-02, -2.4665e-02,\n",
      "          -6.1663e-02,  1.5677e-04],\n",
      "         [ 1.0000e+00, -1.9108e-02, -3.3735e-02, -2.8084e-02, -2.7419e-02,\n",
      "          -3.3408e-01,  9.2415e-03],\n",
      "         [ 1.0000e+00, -1.1514e-02,  0.0000e+00, -1.7773e-03, -5.5798e-04,\n",
      "          -7.6798e-01,  1.0239e-02],\n",
      "         [ 1.0000e+00, -5.9524e-04, -1.1567e-03,  2.7534e-02,  3.0880e-02,\n",
      "          -5.4977e-01, -8.4895e-03],\n",
      "         [ 2.0000e+00,  5.3540e-02,  6.0520e-02,  5.7313e-02,  6.7858e-02,\n",
      "          -1.8781e-01,  1.2769e-03],\n",
      "         [ 1.0000e+00,  7.4739e-02,  2.3978e-02,  1.7089e-02, -4.3675e-02,\n",
      "           1.8683e-01,  1.3790e-02],\n",
      "         [ 1.0000e+00, -5.1613e-02, -2.5064e-02, -1.4915e-02, -2.0181e-03,\n",
      "          -3.1147e-01, -2.8013e-03],\n",
      "         [ 1.0000e+00, -3.1480e-02, -2.8094e-02, -1.4989e-02, -1.4412e-03,\n",
      "          -5.6670e-01, -6.8193e-03],\n",
      "         [ 1.0000e+00, -2.4487e-02, -2.7237e-02, -3.2587e-02, -2.3666e-02,\n",
      "          -2.1793e-01, -5.9428e-03],\n",
      "         [ 1.0000e+00,  3.2498e-02, -8.4525e-03, -1.3541e-03, -1.9563e-02,\n",
      "          -9.5152e-02,  4.9597e-04]],\n",
      "\n",
      "        [[ 1.0000e+00, -5.2265e-02, -5.5532e-02, -5.0363e-02, -3.4342e-02,\n",
      "           1.3553e+00,  3.5236e-02],\n",
      "         [ 1.0000e+00, -3.8961e-02,  1.5461e-02, -6.5531e-02,  2.8681e-02,\n",
      "           2.0682e-01,  5.7518e-03],\n",
      "         [ 1.0000e+00, -1.1648e-02, -6.2500e-03, -3.5608e-03, -1.5167e-02,\n",
      "           1.2238e-01,  2.2392e-03],\n",
      "         [ 1.0000e+00,  1.8463e-02,  3.1847e-02,  3.5323e-02,  3.8634e-02,\n",
      "           7.2320e-02, -7.8078e-03],\n",
      "         [ 3.0000e+00,  4.5737e-02, -7.4667e-03, -1.6940e-03, -3.8994e-02,\n",
      "           3.0655e-01,  1.0226e-03],\n",
      "         [ 3.0000e+00, -6.0377e-02, -1.0112e-02, -2.6072e-02,  4.1667e-02,\n",
      "          -3.3258e-01,  3.3680e-03],\n",
      "         [ 3.0000e+00,  3.4014e-03,  1.3184e-03,  5.5058e-03, -2.6607e-03,\n",
      "           1.1861e-01,  1.1258e-02],\n",
      "         [ 3.0000e+00,  1.3831e-03,  3.9229e-02,  4.1304e-02,  4.7408e-02,\n",
      "           3.2381e-01,  2.5674e-03],\n",
      "         [ 3.0000e+00, -1.5604e-02, -2.0000e-02, -1.9649e-02, -3.1842e-02,\n",
      "           1.3942e-01, -8.8419e-03],\n",
      "         [ 3.0000e+00, -2.2951e-02, -1.5082e-02, -4.0678e-03, -7.4294e-04,\n",
      "          -1.2615e-01, -9.8569e-03]]], dtype=torch.float64)\n",
      "torch.Size([10]) tensor([0, 0, 2, 1, 1, 0, 1, 0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Test out the dataloader\n",
    "sample_batch, sample_labels = next(iter(dataloader(train_features, train_labels)))\n",
    "print(sample_batch.shape, sample_batch)\n",
    "print(sample_labels.shape, sample_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_length = 7,lstm_size = 64, lstm_layers=1, output_size = 3, \n",
    "                               drop_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.input_length = input_length\n",
    "        self.output_size = output_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        ## TODO: define the LSTM\n",
    "        self.lstm = nn.LSTM(input_length, lstm_size, lstm_layers, \n",
    "                            dropout=drop_prob, batch_first=False)\n",
    "        \n",
    "        ## TODO: define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## TODO: define the final, fully-connected output layer\n",
    "        self.fc = nn.Linear(lstm_size, output_size)\n",
    "      \n",
    "    \n",
    "    def forward(self, nn_input, hidden_state):\n",
    "        '''\n",
    "            Perform a forward pass through the network\n",
    "            \n",
    "            Args:\n",
    "                nn_input: the batch of input to NN\n",
    "                hidden_state: The LSTM hidden/cell state tuple\n",
    "                \n",
    "            Returns:\n",
    "                logps: log softmax output\n",
    "                hidden_state: the updated hidden/cell state tuple\n",
    "        '''\n",
    "        # Input -> LSTM\n",
    "        lstm_out, hidden_state = self.lstm(nn_input, hidden)\n",
    "\n",
    "        # Stack up LSTM outputs -- this gets the final LSTM output for each sequence in the batch\n",
    "        lstm_out = lstm_out[-1, :, :]\n",
    "        \n",
    "        # LSTM -> Dense Layer\n",
    "        dense_out = self.dropout(self.fc(lstm_out))\n",
    "        \n",
    "        # Apply Log Softmax to dense output -- sum denominator across columns\n",
    "        logps = F.log_softmax(dense_out, dim=1)\n",
    "        \n",
    "        # Return the final output and the hidden state\n",
    "        return logps, hidden_state\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_(),\n",
    "              weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 7])\n",
      "torch.Size([5, 10, 8])\n",
      "torch.Size([10, 8]) tensor([[ 0.0079, -0.0897,  0.2496, -0.0011,  0.2488, -0.1307,  0.0827, -0.1861],\n",
      "        [ 0.0178, -0.0917,  0.2544, -0.0051,  0.2422, -0.1280,  0.0885, -0.1916],\n",
      "        [-0.0017, -0.0847,  0.2487,  0.0097,  0.2532, -0.1268,  0.0643, -0.1798],\n",
      "        [ 0.0255, -0.0852,  0.2472, -0.0049,  0.2539, -0.1493,  0.0748, -0.1906],\n",
      "        [ 0.0398, -0.0885,  0.2453, -0.0200,  0.2517, -0.1417,  0.0790, -0.2136],\n",
      "        [ 0.0266, -0.0808,  0.2466, -0.0066,  0.2543, -0.1433,  0.0721, -0.2016],\n",
      "        [ 0.0198, -0.0727,  0.2507, -0.0006,  0.2499, -0.1360,  0.0796, -0.1845],\n",
      "        [ 0.0302, -0.1045,  0.2434, -0.0423,  0.2474, -0.1426,  0.0993, -0.2200],\n",
      "        [ 0.0372, -0.0843,  0.2465, -0.0161,  0.2512, -0.1522,  0.0768, -0.2071],\n",
      "        [ 0.0372, -0.0824,  0.2467, -0.0144,  0.2516, -0.1515,  0.0751, -0.2053]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0000,  0.3159,  0.0655],\n",
      "        [-0.0171,  0.3185,  0.0622],\n",
      "        [-0.0000,  0.3140,  0.0589],\n",
      "        [-0.0207,  0.3123,  0.0624],\n",
      "        [-0.0000,  0.3219,  0.0578],\n",
      "        [-0.0221,  0.3150,  0.0570],\n",
      "        [-0.0207,  0.0000,  0.0572],\n",
      "        [-0.0181,  0.3341,  0.0000],\n",
      "        [-0.0197,  0.3179,  0.0594],\n",
      "        [-0.0197,  0.3165,  0.0580]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.2352, -0.9194, -1.1697],\n",
      "        [-1.2474, -0.9118, -1.1681],\n",
      "        [-1.2324, -0.9184, -1.1735],\n",
      "        [-1.2475, -0.9145, -1.1645],\n",
      "        [-1.2352, -0.9134, -1.1775],\n",
      "        [-1.2480, -0.9108, -1.1688],\n",
      "        [-1.1321, -1.1113, -1.0541],\n",
      "        [-1.2356, -0.8834, -1.2175],\n",
      "        [-1.2482, -0.9105, -1.1691],\n",
      "        [-1.2472, -0.9109, -1.1695]], dtype=torch.float64,\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-1.2352, -0.9194, -1.1697],\n",
      "        [-1.2474, -0.9118, -1.1681],\n",
      "        [-1.2324, -0.9184, -1.1735],\n",
      "        [-1.2475, -0.9145, -1.1645],\n",
      "        [-1.2352, -0.9134, -1.1775],\n",
      "        [-1.2480, -0.9108, -1.1688],\n",
      "        [-1.1321, -1.1113, -1.0541],\n",
      "        [-1.2356, -0.8834, -1.2175],\n",
      "        [-1.2482, -0.9105, -1.1691],\n",
      "        [-1.2472, -0.9109, -1.1695]], dtype=torch.float64,\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = StockClassifier(input_length=7, lstm_size=8, lstm_layers=2, output_size=3, drop_prob=0.1).double()\n",
    "hidden = model.init_hidden(10)\n",
    "logps, _ = model.forward(sample_batch, hidden)\n",
    "print(logps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockClassifier(\n",
       "  (lstm): LSTM(7, 16, num_layers=2, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Ensure that our model is set to 'double' as our volume value requires Float64\n",
    "model = StockClassifier(input_length=7, lstm_size=16, lstm_layers=2, output_size=3, drop_prob=0.5).double()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "Epoch: 1/15... Step: 10... Train Loss: 1.148918... Val Loss: 1.078245... Accuracy: 40.952382%...\n",
      "Epoch: 1/15... Step: 20... Train Loss: 1.096682... Val Loss: 1.090572... Accuracy: 40.000001%...\n",
      "Epoch: 1/15... Step: 30... Train Loss: 1.062857... Val Loss: 1.088714... Accuracy: 40.000001%...\n",
      "Epoch: 1/15... Step: 40... Train Loss: 1.122003... Val Loss: 1.094084... Accuracy: 40.000001%...\n",
      "Epoch: 1/15... Step: 50... Train Loss: 1.046166... Val Loss: 1.095366... Accuracy: 40.000001%...\n",
      "Epoch: 1/15... Step: 60... Train Loss: 1.098209... Val Loss: 1.097055... Accuracy: 40.000001%...\n",
      "Epoch: 1/15... Step: 70... Train Loss: 1.096759... Val Loss: 1.094321... Accuracy: 39.523810%...\n",
      "Epoch: 1/15... Step: 80... Train Loss: 1.121530... Val Loss: 1.094675... Accuracy: 43.809524%...\n",
      "Starting Epoch 2\n",
      "Epoch: 2/15... Step: 10... Train Loss: 1.113535... Val Loss: 1.098793... Accuracy: 39.523810%...\n",
      "Epoch: 2/15... Step: 20... Train Loss: 1.059956... Val Loss: 1.104020... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 30... Train Loss: 1.065796... Val Loss: 1.115937... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 40... Train Loss: 1.082657... Val Loss: 1.110689... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 50... Train Loss: 1.093933... Val Loss: 1.105120... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 60... Train Loss: 1.109965... Val Loss: 1.090798... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 70... Train Loss: 1.082563... Val Loss: 1.091669... Accuracy: 40.000001%...\n",
      "Epoch: 2/15... Step: 80... Train Loss: 1.048521... Val Loss: 1.098247... Accuracy: 40.000001%...\n",
      "Starting Epoch 3\n",
      "Epoch: 3/15... Step: 10... Train Loss: 1.066812... Val Loss: 1.098259... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 20... Train Loss: 1.081779... Val Loss: 1.089190... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 30... Train Loss: 1.104904... Val Loss: 1.087242... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 40... Train Loss: 1.101819... Val Loss: 1.086666... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 50... Train Loss: 1.080726... Val Loss: 1.086684... Accuracy: 40.476191%...\n",
      "Epoch: 3/15... Step: 60... Train Loss: 1.125454... Val Loss: 1.086437... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 70... Train Loss: 1.128950... Val Loss: 1.086409... Accuracy: 40.000001%...\n",
      "Epoch: 3/15... Step: 80... Train Loss: 1.075323... Val Loss: 1.090009... Accuracy: 40.000001%...\n",
      "Starting Epoch 4\n",
      "Epoch: 4/15... Step: 10... Train Loss: 1.090970... Val Loss: 1.090799... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 20... Train Loss: 1.095685... Val Loss: 1.087207... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 30... Train Loss: 1.066210... Val Loss: 1.087794... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 40... Train Loss: 1.103559... Val Loss: 1.092050... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 50... Train Loss: 1.099037... Val Loss: 1.087617... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 60... Train Loss: 1.079624... Val Loss: 1.090447... Accuracy: 40.000001%...\n",
      "Epoch: 4/15... Step: 70... Train Loss: 1.078024... Val Loss: 1.080209... Accuracy: 40.476191%...\n",
      "Epoch: 4/15... Step: 80... Train Loss: 1.142406... Val Loss: 1.077043... Accuracy: 40.476191%...\n",
      "Starting Epoch 5\n",
      "Epoch: 5/15... Step: 10... Train Loss: 1.098067... Val Loss: 1.082755... Accuracy: 39.523810%...\n",
      "Epoch: 5/15... Step: 20... Train Loss: 1.083128... Val Loss: 1.072583... Accuracy: 40.476191%...\n",
      "Epoch: 5/15... Step: 30... Train Loss: 1.093367... Val Loss: 1.081393... Accuracy: 40.952381%...\n",
      "Epoch: 5/15... Step: 40... Train Loss: 1.115971... Val Loss: 1.101353... Accuracy: 37.142858%...\n",
      "Epoch: 5/15... Step: 50... Train Loss: 1.154747... Val Loss: 1.097561... Accuracy: 41.428572%...\n",
      "Epoch: 5/15... Step: 60... Train Loss: 1.022682... Val Loss: 1.097316... Accuracy: 39.523810%...\n",
      "Epoch: 5/15... Step: 70... Train Loss: 1.111456... Val Loss: 1.086713... Accuracy: 42.857144%...\n",
      "Epoch: 5/15... Step: 80... Train Loss: 1.073818... Val Loss: 1.090973... Accuracy: 37.142858%...\n",
      "Starting Epoch 6\n",
      "Epoch: 6/15... Step: 10... Train Loss: 1.150564... Val Loss: 1.088947... Accuracy: 35.238096%...\n",
      "Epoch: 6/15... Step: 20... Train Loss: 1.088657... Val Loss: 1.069943... Accuracy: 42.857144%...\n",
      "Epoch: 6/15... Step: 30... Train Loss: 1.076279... Val Loss: 1.080714... Accuracy: 41.428572%...\n",
      "Epoch: 6/15... Step: 40... Train Loss: 1.095554... Val Loss: 1.127352... Accuracy: 18.571429%...\n",
      "Epoch: 6/15... Step: 50... Train Loss: 1.067710... Val Loss: 1.094635... Accuracy: 40.476191%...\n",
      "Epoch: 6/15... Step: 60... Train Loss: 1.073845... Val Loss: 1.108311... Accuracy: 31.904762%...\n",
      "Epoch: 6/15... Step: 70... Train Loss: 1.096848... Val Loss: 1.091625... Accuracy: 40.000001%...\n",
      "Epoch: 6/15... Step: 80... Train Loss: 1.121577... Val Loss: 1.121353... Accuracy: 30.000001%...\n",
      "Starting Epoch 7\n",
      "Epoch: 7/15... Step: 10... Train Loss: 1.074718... Val Loss: 1.121999... Accuracy: 26.666667%...\n",
      "Epoch: 7/15... Step: 20... Train Loss: 1.086204... Val Loss: 1.086029... Accuracy: 42.857144%...\n",
      "Epoch: 7/15... Step: 30... Train Loss: 1.035049... Val Loss: 1.099978... Accuracy: 34.285715%...\n",
      "Epoch: 7/15... Step: 40... Train Loss: 1.117289... Val Loss: 1.112735... Accuracy: 25.714286%...\n",
      "Epoch: 7/15... Step: 50... Train Loss: 1.076792... Val Loss: 1.069369... Accuracy: 43.333334%...\n",
      "Epoch: 7/15... Step: 60... Train Loss: 1.060423... Val Loss: 1.091367... Accuracy: 35.714286%...\n",
      "Epoch: 7/15... Step: 70... Train Loss: 1.073618... Val Loss: 1.082690... Accuracy: 44.285715%...\n",
      "Epoch: 7/15... Step: 80... Train Loss: 1.133690... Val Loss: 1.108304... Accuracy: 32.857144%...\n",
      "Starting Epoch 8\n",
      "Epoch: 8/15... Step: 10... Train Loss: 1.098665... Val Loss: 1.138731... Accuracy: 16.666667%...\n",
      "Epoch: 8/15... Step: 20... Train Loss: 1.120804... Val Loss: 1.101214... Accuracy: 44.761905%...\n",
      "Epoch: 8/15... Step: 30... Train Loss: 1.108561... Val Loss: 1.115805... Accuracy: 26.190477%...\n",
      "Epoch: 8/15... Step: 40... Train Loss: 1.147597... Val Loss: 1.141523... Accuracy: 15.714286%...\n",
      "Epoch: 8/15... Step: 50... Train Loss: 1.075101... Val Loss: 1.088333... Accuracy: 39.523810%...\n",
      "Epoch: 8/15... Step: 60... Train Loss: 1.081764... Val Loss: 1.114164... Accuracy: 22.380953%...\n",
      "Epoch: 8/15... Step: 70... Train Loss: 1.123534... Val Loss: 1.107279... Accuracy: 33.809524%...\n",
      "Epoch: 8/15... Step: 80... Train Loss: 1.070814... Val Loss: 1.127491... Accuracy: 22.857143%...\n",
      "Starting Epoch 9\n",
      "Epoch: 9/15... Step: 10... Train Loss: 1.078832... Val Loss: 1.139974... Accuracy: 20.952381%...\n",
      "Epoch: 9/15... Step: 20... Train Loss: 1.072330... Val Loss: 1.102110... Accuracy: 41.428572%...\n",
      "Epoch: 9/15... Step: 30... Train Loss: 1.016212... Val Loss: 1.093696... Accuracy: 40.000001%...\n",
      "Epoch: 9/15... Step: 40... Train Loss: 1.045742... Val Loss: 1.105927... Accuracy: 40.000001%...\n",
      "Epoch: 9/15... Step: 50... Train Loss: 1.092899... Val Loss: 1.069767... Accuracy: 40.000001%...\n",
      "Epoch: 9/15... Step: 60... Train Loss: 1.066972... Val Loss: 1.089472... Accuracy: 40.000001%...\n",
      "Epoch: 9/15... Step: 70... Train Loss: 1.105993... Val Loss: 1.076168... Accuracy: 40.952381%...\n",
      "Epoch: 9/15... Step: 80... Train Loss: 1.077245... Val Loss: 1.090936... Accuracy: 32.380953%...\n",
      "Starting Epoch 10\n",
      "Epoch: 10/15... Step: 10... Train Loss: 1.064807... Val Loss: 1.116201... Accuracy: 24.285715%...\n",
      "Epoch: 10/15... Step: 20... Train Loss: 1.097177... Val Loss: 1.096158... Accuracy: 41.904763%...\n",
      "Epoch: 10/15... Step: 30... Train Loss: 1.015350... Val Loss: 1.114110... Accuracy: 25.238096%...\n",
      "Epoch: 10/15... Step: 40... Train Loss: 1.179546... Val Loss: 1.142996... Accuracy: 18.095238%...\n",
      "Epoch: 10/15... Step: 50... Train Loss: 1.093096... Val Loss: 1.090508... Accuracy: 48.571429%...\n",
      "Epoch: 10/15... Step: 60... Train Loss: 1.055067... Val Loss: 1.133768... Accuracy: 19.047619%...\n",
      "Epoch: 10/15... Step: 70... Train Loss: 1.131382... Val Loss: 1.125226... Accuracy: 34.285715%...\n",
      "Epoch: 10/15... Step: 80... Train Loss: 1.008047... Val Loss: 1.143247... Accuracy: 20.952381%...\n",
      "Starting Epoch 11\n",
      "Epoch: 11/15... Step: 10... Train Loss: 1.069779... Val Loss: 1.136668... Accuracy: 11.904762%...\n",
      "Epoch: 11/15... Step: 20... Train Loss: 1.113611... Val Loss: 1.095731... Accuracy: 42.380953%...\n",
      "Epoch: 11/15... Step: 30... Train Loss: 1.052105... Val Loss: 1.105768... Accuracy: 32.857144%...\n",
      "Epoch: 11/15... Step: 40... Train Loss: 1.141648... Val Loss: 1.130425... Accuracy: 26.190477%...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/15... Step: 50... Train Loss: 1.095164... Val Loss: 1.089072... Accuracy: 44.285715%...\n",
      "Epoch: 11/15... Step: 60... Train Loss: 1.058963... Val Loss: 1.120739... Accuracy: 30.000001%...\n",
      "Epoch: 11/15... Step: 70... Train Loss: 1.099737... Val Loss: 1.095083... Accuracy: 41.428572%...\n",
      "Epoch: 11/15... Step: 80... Train Loss: 1.057742... Val Loss: 1.105617... Accuracy: 33.333334%...\n",
      "Starting Epoch 12\n",
      "Epoch: 12/15... Step: 10... Train Loss: 1.071070... Val Loss: 1.113232... Accuracy: 25.714286%...\n",
      "Epoch: 12/15... Step: 20... Train Loss: 1.097188... Val Loss: 1.107307... Accuracy: 39.523810%...\n",
      "Epoch: 12/15... Step: 30... Train Loss: 1.125271... Val Loss: 1.130232... Accuracy: 29.047620%...\n",
      "Epoch: 12/15... Step: 40... Train Loss: 1.108709... Val Loss: 1.142013... Accuracy: 14.285715%...\n",
      "Epoch: 12/15... Step: 50... Train Loss: 1.065332... Val Loss: 1.109635... Accuracy: 42.380953%...\n",
      "Epoch: 12/15... Step: 60... Train Loss: 1.009452... Val Loss: 1.106175... Accuracy: 29.047620%...\n",
      "Epoch: 12/15... Step: 70... Train Loss: 1.072430... Val Loss: 1.099115... Accuracy: 43.809524%...\n",
      "Epoch: 12/15... Step: 80... Train Loss: 1.015864... Val Loss: 1.111581... Accuracy: 31.428572%...\n",
      "Starting Epoch 13\n",
      "Epoch: 13/15... Step: 10... Train Loss: 1.085172... Val Loss: 1.127860... Accuracy: 19.047620%...\n",
      "Epoch: 13/15... Step: 20... Train Loss: 1.134703... Val Loss: 1.081680... Accuracy: 40.952382%...\n",
      "Epoch: 13/15... Step: 30... Train Loss: 1.097105... Val Loss: 1.107458... Accuracy: 28.571429%...\n",
      "Epoch: 13/15... Step: 40... Train Loss: 1.118949... Val Loss: 1.142347... Accuracy: 14.285715%...\n",
      "Epoch: 13/15... Step: 50... Train Loss: 1.079665... Val Loss: 1.069894... Accuracy: 45.238096%...\n",
      "Epoch: 13/15... Step: 60... Train Loss: 1.086922... Val Loss: 1.140109... Accuracy: 15.714286%...\n",
      "Epoch: 13/15... Step: 70... Train Loss: 1.107494... Val Loss: 1.079063... Accuracy: 39.523810%...\n",
      "Epoch: 13/15... Step: 80... Train Loss: 1.084916... Val Loss: 1.102290... Accuracy: 31.428572%...\n",
      "Starting Epoch 14\n",
      "Epoch: 14/15... Step: 10... Train Loss: 1.093703... Val Loss: 1.145867... Accuracy: 17.619048%...\n",
      "Epoch: 14/15... Step: 20... Train Loss: 1.131766... Val Loss: 1.080139... Accuracy: 40.000001%...\n",
      "Epoch: 14/15... Step: 30... Train Loss: 1.090323... Val Loss: 1.129040... Accuracy: 20.476191%...\n",
      "Epoch: 14/15... Step: 40... Train Loss: 1.198284... Val Loss: 1.151509... Accuracy: 14.285715%...\n",
      "Epoch: 14/15... Step: 50... Train Loss: 1.073355... Val Loss: 1.092409... Accuracy: 37.619048%...\n",
      "Epoch: 14/15... Step: 60... Train Loss: 1.069547... Val Loss: 1.130924... Accuracy: 18.571429%...\n",
      "Epoch: 14/15... Step: 70... Train Loss: 1.101799... Val Loss: 1.080910... Accuracy: 40.476191%...\n",
      "Epoch: 14/15... Step: 80... Train Loss: 1.033648... Val Loss: 1.105060... Accuracy: 33.333334%...\n",
      "Starting Epoch 15\n",
      "Epoch: 15/15... Step: 10... Train Loss: 1.049334... Val Loss: 1.159605... Accuracy: 15.238096%...\n",
      "Epoch: 15/15... Step: 20... Train Loss: 1.094032... Val Loss: 1.071621... Accuracy: 40.476191%...\n",
      "Epoch: 15/15... Step: 30... Train Loss: 1.078547... Val Loss: 1.132360... Accuracy: 21.904762%...\n",
      "Epoch: 15/15... Step: 40... Train Loss: 1.171392... Val Loss: 1.161542... Accuracy: 11.428572%...\n",
      "Epoch: 15/15... Step: 50... Train Loss: 1.107327... Val Loss: 1.087188... Accuracy: 44.285715%...\n",
      "Epoch: 15/15... Step: 60... Train Loss: 1.051064... Val Loss: 1.138729... Accuracy: 20.000000%...\n",
      "Epoch: 15/15... Step: 70... Train Loss: 1.068906... Val Loss: 1.109605... Accuracy: 29.047620%...\n",
      "Epoch: 15/15... Step: 80... Train Loss: 0.987745... Val Loss: 1.137682... Accuracy: 21.904763%...\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "learning_rate = 0.003\n",
    "clip = 5\n",
    "input_length=7\n",
    "\n",
    "print_every = 10\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "training_losses = [x for x in range(epochs)]\n",
    "validation_losses = [x for x in range(epochs)]\n",
    "accuracies = [x for x in range(epochs)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting Epoch {}'.format(epoch+1))\n",
    "    steps = 0\n",
    "    \n",
    "    for t_batch, t_labels in dataloader(train_features, train_labels, batch_size=batch_size\n",
    "                                        ,input_length=input_length, sequence_length=seq_length):\n",
    "        steps += 1\n",
    "    \n",
    "        # Initialize Hidden/Cell state -- batch size is dynamic to account for batches that are not full\n",
    "        hidden = model.init_hidden(t_batch.shape[1])\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        \n",
    "        # Set tensors to correct device -- GPU or CPU\n",
    "        t_batch, t_labels = t_batch.to(device), t_labels.to(device)\n",
    "        for each in hidden:\n",
    "            each.to(device)\n",
    "            \n",
    "        # Zero out gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Run data through model -- output is output and new hidden/cell state\n",
    "        output, hidden = model(t_batch, hidden)\n",
    "        \n",
    "        # Calculate loss and perform back prop -- clip grads if necessary\n",
    "        loss = criterion(output, t_labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # Take optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # VALIDATION OF MODEL#\n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            accuracy = []\n",
    "            #with torch.no_grad():\n",
    "            for val_batch, val_labels in dataloader(test_features, test_labels, batch_size=batch_size\n",
    "                                                    ,input_length=input_length, sequence_length=seq_length):\n",
    "\n",
    "                #Init hidden state -- again we have a dynamic batch size here\n",
    "                val_hidden = model.init_hidden(val_batch.shape[1])\n",
    "                val_hidden = tuple([each.data for each in val_hidden])\n",
    "\n",
    "                # Set device for tensors\n",
    "                val_batch, val_labels = val_batch.to(device), val_labels.to(device)\n",
    "                for each in val_hidden:\n",
    "                    each.to(device)\n",
    "\n",
    "                # Run data through network\n",
    "                val_out, val_hidden = model(val_batch, val_hidden)\n",
    "                \n",
    "\n",
    "                # Calculate and record loss\n",
    "                val_loss = criterion(val_out, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                # Calculate accuracy of predictions\n",
    "                ps = torch.exp(val_out)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == val_labels.view(*top_class.shape)\n",
    "                accuracy.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "            # Print out metrics\n",
    "            print('Epoch: {}/{}...'.format(epoch+1, epochs),\n",
    "                  'Step: {}...'.format(steps),\n",
    "                  'Train Loss: {:.6f}...'.format(loss.item()),\n",
    "                  'Val Loss: {:.6f}...'.format(np.mean(val_losses)),\n",
    "                  'Accuracy: {:.6f}%...'.format(np.mean(accuracy) * 100))\n",
    "            \n",
    "            # Record metrics\n",
    "            training_losses[epoch] = loss.item()\n",
    "            validation_losses[epoch] = np.mean(val_losses)\n",
    "            accuracies[epoch] = np.mean(accuracy) * 100\n",
    "            \n",
    "            # Set back to training mode\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop will error out if you try to run it multiple times. This happens because the state of the dataloaders has not changed since the last run, and therefore you'll run out of data very quickly. When this happens, go back to the 'Create test and validation data' cell and re-run. This will reset the data in the generators and allow you to try and train again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loss Plot\n",
    "plt.plot(training_losses)#, validation_losses)\n",
    "plt.plot(validation_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy plot\n",
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
