{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Empty Pipeline with Screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resources\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors.basic import SimpleMovingAverage\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "# Create a screen for our Pipeline\n",
    "mean_close_10 = SimpleMovingAverage(\n",
    "    inputs=[USEquityPricing.close],\n",
    "    window_length=10\n",
    ")\n",
    "\n",
    "universe = mean_close_10 > 10\n",
    "\n",
    "# Create an empty Pipeline with the given screen\n",
    "pipeline = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zipline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from zipline.utils.calendars import get_calendar\n",
    "from zipline.data import bundles\n",
    "\n",
    "# Name of bundle\n",
    "EOD_BUNDLE_NAME = 'quantopian-quandl'\n",
    "\n",
    "# Load the data bundle\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Setup the engine to look at the top 500 stocks who have had the highest rolling Average Dollar Volume\n",
    "# over a 120-day window -- This is arbitrary and we can use this parameter to refine which stocks we\n",
    "# want in our universe\n",
    "universe = mean_close_10.top(500) \n",
    "\n",
    "# Select the trading calendar that will be used as a reference when slicing the data\n",
    "trading_calendar = get_calendar('NYSE') \n",
    "\n",
    "# Load the bundle we configured in the previous step into the engine\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Create the engine -- the details of this function are in the utils.py file\n",
    "engine = helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Pipeline as Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"287pt\" viewBox=\"0.00 0.00 210.00 287.00\" width=\"210pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 283)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-283 206,-283 206,4 -4,4\" stroke=\"transparent\"/>\n",
       "<g class=\"cluster\" id=\"clust1\">\n",
       "<title>cluster_Output</title>\n",
       "<polygon fill=\"#ffec8b\" points=\"31,-8 31,-85 171,-85 171,-8 31,-8\" stroke=\"#ffec8b\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-15.8\">Output</text>\n",
       "</g>\n",
       "<g class=\"cluster\" id=\"clust2\">\n",
       "<title>cluster_Input</title>\n",
       "<polygon fill=\"#ffec8b\" points=\"8,-179 8,-271 194,-271 194,-179 8,-179\" stroke=\"#ffec8b\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-255.8\">Input</text>\n",
       "</g>\n",
       "<!-- 4464477744 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4464477744</title>\n",
       "<polygon fill=\"#ccebc5\" points=\"163,-77 39,-77 39,-39 163,-39 163,-77\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"47\" y=\"-61.8\">Expression:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"47\" y=\"-46.8\">  x_0 &gt; (1.00E+01)</text>\n",
       "</g>\n",
       "<!-- 4909592984 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4909592984</title>\n",
       "<polygon fill=\"#fbb4ae\" points=\"185.5,-240 16.5,-240 16.5,-187 185.5,-187 185.5,-240\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-224.8\">BoundColumn:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-209.8\">  Dataset: USEquityPricing</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-194.8\">  Column: close</text>\n",
       "</g>\n",
       "<!-- 4466440736 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4466440736</title>\n",
       "<polygon fill=\"#b3cde3\" points=\"177,-151 25,-151 25,-113 177,-113 177,-151\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"33\" y=\"-135.8\">SimpleMovingAverage:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"33\" y=\"-120.8\">  window_length: 10</text>\n",
       "</g>\n",
       "<!-- 4909592984&#45;&gt;4466440736 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4909592984-&gt;4466440736</title>\n",
       "<path d=\"M101,-186.8139C101,-186.8139 101,-161.2531 101,-161.2531\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"104.5001,-161.253 101,-151.2531 97.5001,-161.2531 104.5001,-161.253\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4466440736&#45;&gt;4464477744 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4466440736-&gt;4464477744</title>\n",
       "<path d=\"M101,-112.9432C101,-112.9432 101,-87.2495 101,-87.2495\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"104.5001,-87.2494 101,-77.2495 97.5001,-87.2495 104.5001,-87.2494\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Render the pipeline as a DAG\n",
    "pipeline.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the start and end dates\n",
    "start_date = pd.Timestamp('2017-01-05', tz = 'utc')\n",
    "end_date = pd.Timestamp('2017-01-05', tz = 'utc')\n",
    "\n",
    "# Run our pipeline for the given start and end dates\n",
    "pipeline_output = engine.run_pipeline(pipeline, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Universe Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values in index level 1 and save them to a list\n",
    "universe_tickers = pipeline_output.index.get_level_values(1).values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "# Create a data portal\n",
    "data_portal = DataPortal(bundle_data.asset_finder,\n",
    "                         trading_calendar = trading_calendar,\n",
    "                         first_trading_day = bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "                         equity_daily_reader = bundle_data.equity_daily_bar_reader,\n",
    "                         adjustment_reader = bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Historical Data\n",
    "\n",
    "Get the OHLC + V data for a given time period. This data will be split into individual dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_field_data(data_portal, trading_calendar, assets, start_date, end_date, field):\n",
    "    \n",
    "    # Set the given start and end dates to Timestamps. The frequency string C is used to\n",
    "    # indicate that a CustomBusinessDay DateOffset is used\n",
    "    end_dt = pd.Timestamp(end_date, tz='UTC', freq='C')\n",
    "    start_dt = pd.Timestamp(start_date, tz='UTC', freq='C')\n",
    "\n",
    "    # Get the locations of the start and end dates\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    # return the historical data for the given window\n",
    "    return data_portal.get_history_window(assets=assets, end_dt=end_dt, bar_count=end_loc - start_loc,\n",
    "                                          frequency='1d',\n",
    "                                          field=field,\n",
    "                                          data_frequency='daily')\n",
    "\n",
    "# The window of data to obtain\n",
    "start_date = '2015-01-05'\n",
    "end_data = '2017-01-05'\n",
    "\n",
    "# Get the open data\n",
    "open_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                          start_date, end_date, 'open')\n",
    "\n",
    "# Get the high data\n",
    "high_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'high')\n",
    "\n",
    "# Get the low data\n",
    "low_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                         start_date, end_date, 'low')\n",
    "\n",
    "# Get the closing data\n",
    "close_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'close') \n",
    "\n",
    "# Get the volume data\n",
    "volume_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                            start_date, end_date, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine OHLC dataframes into singular dataframe\n",
    "Here we combine the four individual dataframes representing OHLC + V data into one historical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import pytz\n",
    "\n",
    "# Loop through each universe ticker and create a combined dataframe for that ticker. Store these\n",
    "# dataframes in an OrderedDict to use later in panel creation\n",
    "historical_data = OrderedDict()\n",
    "historical_minor_axis = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "for ticker in universe_tickers:\n",
    "    # Get individual series representing the OHLCV data\n",
    "    open_series = open_data[ticker]\n",
    "    high_series = high_data[ticker]\n",
    "    low_series = low_data[ticker]\n",
    "    close_series = close_data[ticker]\n",
    "    volume_series = volume_data[ticker]\n",
    "    \n",
    "    # Combine these series into 1 dataframe\n",
    "    columns = historical_minor_axis\n",
    "    df = pd.concat([open_series,high_series, low_series, close_series, volume_series], axis=1)\n",
    "    df.columns = columns    \n",
    "    \n",
    "    # Save this dataframe to historical_dfs\n",
    "    symbol = helper.beautify_ticker(ticker)\n",
    "    historical_data[symbol] = df\n",
    "\n",
    "# Create panel out of historical data\n",
    "historical_panel = pd.Panel(historical_data)\n",
    "historical_panel.minor_axis = historical_minor_axis\n",
    "historical_panel.major_axis = pd.to_datetime(historical_panel.major_axis)\n",
    "historical_panel.major_axis = historical_panel.major_axis.tz_convert(pytz.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate P&F Chart from Historical Data\n",
    "Use combined historical dataframe to generate a P&F chart for any ticker included in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  AAPL  (2017-01-05 o: 115.92 h: 116.86 l: 115.81 c: 116.61)\n",
      "  1.00% box, 3 box reversal, hl method\n",
      "  signal: buy status: bull confirmed\n",
      "\n",
      " 118.87|                                                                    |118.87\n",
      " 117.69|                                                    x   u       x   |117.69\n",
      " 116.52|                                                    x d u d     x   |<< 116.61\n",
      " 115.37|                                                x   u d u d     x   |115.37\n",
      " 114.23|                                                x d u d   d     x   |114.23\n",
      " 113.10|                                                x d A     d     x   |113.10\n",
      " 111.98|                                                x d       B x   u   |111.98\n",
      " 110.87|                                                x         o x C u   |110.87\n",
      " 109.77|                        x   u                   x         o x d u   |109.77\n",
      " 108.68|                        4 d u d             x   x         o x d     |108.68\n",
      " 107.61|                        x d u d             x d u         o u       |107.61\n",
      " 106.54|                        x d   d             x d u         o u       |106.54\n",
      " 105.49|                        x     d             x d u         o u       |105.49\n",
      " 104.44|                        x     o             8 9 u         o         |104.44\n",
      " 103.41|                        x     o             x o u                   |103.41\n",
      " 102.38|                        x     o             u o                     |102.38\n",
      " 101.37|                        x     o             u                       |101.37\n",
      " 100.37|                        x     o     u       u                       |100.37\n",
      "  99.37|                        x     o x   u d x   u                       |99.37\n",
      "  98.39|        x               x     o x 6 u d x d u                       |98.39\n",
      "  97.42|  d     x d             3     o x d u d x d u                       |97.42\n",
      "  96.45|  d u   x d         x   x     o x d   d x d u                       |96.45\n",
      "  95.50|  d u d u d 2       x d u     o x     o 7 o                         |95.50\n",
      "  94.55|  o u d u d u d u   u d u     o x     o u                           |94.55\n",
      "  93.61|  o   d u d u d u d u d u     o x     o u                           |93.61\n",
      "  92.69|      d u d u d u d u o       o u     o u                           |92.69\n",
      "  91.77|      d   d u o   d           o u     o u                           |91.77\n",
      "  90.86|          o                   5 u     o                             |90.86\n",
      "  89.96|                              o u                                   |89.96\n",
      "  89.07|                              o                                     |89.07\n",
      "  88.19|                                                                    |88.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pnf\n",
    "# Test by creating AAPL P&F Chart\n",
    "aapl_pf = pnf.generate_pf_chart('AAPL', historical_panel)\n",
    "print(aapl_pf.chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Relative Strength Chart\n",
    "Use the OHLC data for two stocks to create a RS chart. We will calculate the ratio between the closing price of the two securities on a daily basis, and record this price as all four values of OHLC in the new, combined dataframe. This dataframe can then be used to construct a P&F chart of these ratios, giving us a relative strength chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  AAPL_MSFT  (2017-01-05 o: 1.87 h: 1.87 l: 1.87 c: 1.87)\n",
      "  1.00% box, 3 box reversal, hl method\n",
      "  signal: sell status: bear confirmed\n",
      "\n",
      "   2.07|                                                        |2.07\n",
      "   2.05|                  u                               x     |2.05\n",
      "   2.03|              x   u d                             u d   |2.03\n",
      "   2.01|              4 d u d                         x   u d   |2.01\n",
      "   1.99|          x   u d u d                         x d u d   |1.99\n",
      "   1.97|          x d u d u d                         x d A d   |1.97\n",
      "   1.95|  x   x   x d u d u d         x               x d   o   |1.95\n",
      "   1.93|  x d x d 3 d   d u d     x   u d             x     o   |1.93\n",
      "   1.91|  x d x d u     d   o u   x 6 u d u       x   u     o   |1.91\n",
      "   1.89|  x d x d u         o u d x d u d u 7 u   x d u     B   |1.89\n",
      "   1.88|  x d x d u         5 u d x d   d u d u d 8 d u     o   |<< 1.87\n",
      "   1.86|  x d u o           o   d x     o   d u d x d 9     o   |1.86\n",
      "   1.84|    d u                 o x         o u d u o       o   |1.84\n",
      "   1.82|    o u                 o u         o   d u         o   |1.82\n",
      "   1.80|    o u                 o u             d u             |1.80\n",
      "   1.78|    o u                 o u             o u             |1.78\n",
      "   1.77|    2                   o               o u             |1.77\n",
      "   1.75|                                        o u             |1.75\n",
      "   1.73|                                        o u             |1.73\n",
      "   1.71|                                        o               |1.71\n",
      "   1.70|                                                        |1.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a RS chart\n",
    "chart = pnf.generate_rs_chart('AAPL', 'MSFT', historical_panel)\n",
    "print(chart.chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RS Matrix\n",
    "Create a relative strength matrix amongst a given set of tickers. This matrix will generate an RS chart for each ticker against each other ticker, and then determine 1. If the numerator is giving a buy or sell signal, and 2. if the numerator is in a column of Xs or Os. The counts of these signals and columns will be tallied up, and the highest ranked stock will have the most total buy signals and X columns versus the other stocks in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_count</th>\n",
       "      <th>buy_count</th>\n",
       "      <th>total</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>GE</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>GM</th>\n",
       "      <th>NVDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>x_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>x_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>x_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x_buy</td>\n",
       "      <td>x_buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>x_sell</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x_sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>o_sell</td>\n",
       "      <td>o_buy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_count  buy_count  total    AAPL    MSFT      GE    TSLA      GM  \\\n",
       "AAPL        2          2      4     NaN  o_sell   x_buy  o_sell  o_sell   \n",
       "MSFT        2          4      6   o_buy     NaN   x_buy  o_sell   o_buy   \n",
       "GE          2          4      6   o_buy   o_buy     NaN  o_sell   x_buy   \n",
       "TSLA        5          5     10   x_buy   x_buy   x_buy     NaN   x_buy   \n",
       "GM          2          0      2  o_sell  o_sell  x_sell  o_sell     NaN   \n",
       "NVDA        0          4      4   o_buy   o_buy   o_buy  o_sell   o_buy   \n",
       "\n",
       "        NVDA  \n",
       "AAPL   x_buy  \n",
       "MSFT   x_buy  \n",
       "GE     x_buy  \n",
       "TSLA   x_buy  \n",
       "GM    x_sell  \n",
       "NVDA     NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the RS Matrix generation function we created above\n",
    "pnf.run_rs_matrix(['AAPL', 'MSFT', 'GE', 'TSLA', 'GM', 'NVDA'], historical_panel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zipline]",
   "language": "python",
   "name": "conda-env-zipline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
