{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Empty Pipeline with Screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resources\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "\n",
    "# Create a screen for our Pipeline\n",
    "universe = AverageDollarVolume(window_length=60) > 50000\n",
    "\n",
    "# Create an empty Pipeline with the given screen\n",
    "pipeline = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zipline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from zipline.utils.calendars import get_calendar\n",
    "from zipline.data import bundles\n",
    "\n",
    "# Name of bundle\n",
    "EOD_BUNDLE_NAME = 'quantopian-quandl'\n",
    "\n",
    "# Load the data bundle\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Setup the engine to look at the top 500 stocks who have had the highest rolling Average Dollar Volume\n",
    "# over a 120-day window -- This is arbitrary and we can use this parameter to refine which stocks we\n",
    "# want in our universe\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "\n",
    "# Select the trading calendar that will be used as a reference when slicing the data\n",
    "trading_calendar = get_calendar('NYSE') \n",
    "\n",
    "# Load the bundle we configured in the previous step into the engine\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Create the engine -- the details of this function are in the utils.py file\n",
    "engine = helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Pipeline as Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"287pt\" viewBox=\"0.00 0.00 397.00 287.00\" width=\"397pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 283)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-283 393,-283 393,4 -4,4\" stroke=\"transparent\"/>\n",
       "<g class=\"cluster\" id=\"clust1\">\n",
       "<title>cluster_Output</title>\n",
       "<polygon fill=\"#ffec8b\" points=\"124,-8 124,-85 264,-85 264,-8 124,-8\" stroke=\"#ffec8b\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-15.8\">Output</text>\n",
       "</g>\n",
       "<g class=\"cluster\" id=\"clust2\">\n",
       "<title>cluster_Input</title>\n",
       "<polygon fill=\"#ffec8b\" points=\"8,-179 8,-271 381,-271 381,-179 8,-179\" stroke=\"#ffec8b\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-255.8\">Input</text>\n",
       "</g>\n",
       "<!-- 4466087416 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4466087416</title>\n",
       "<polygon fill=\"#ccebc5\" points=\"256,-77 132,-77 132,-39 256,-39 256,-77\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"140\" y=\"-61.8\">Expression:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"140\" y=\"-46.8\">  x_0 &gt; (5.00E+04)</text>\n",
       "</g>\n",
       "<!-- 4911160960 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4911160960</title>\n",
       "<polygon fill=\"#fbb4ae\" points=\"372.5,-240 203.5,-240 203.5,-187 372.5,-187 372.5,-240\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"211.5\" y=\"-224.8\">BoundColumn:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"211.5\" y=\"-209.8\">  Dataset: USEquityPricing</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"211.5\" y=\"-194.8\">  Column: close</text>\n",
       "</g>\n",
       "<!-- 4468037392 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4468037392</title>\n",
       "<polygon fill=\"#b3cde3\" points=\"268.5,-151 119.5,-151 119.5,-113 268.5,-113 268.5,-151\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"127.5\" y=\"-135.8\">AverageDollarVolume:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"127.5\" y=\"-120.8\">  window_length: 60</text>\n",
       "</g>\n",
       "<!-- 4911160960&#45;&gt;4468037392 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4911160960-&gt;4468037392</title>\n",
       "<path d=\"M236,-186.8139C236,-186.8139 236,-161.2531 236,-161.2531\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"239.5001,-161.253 236,-151.2531 232.5001,-161.2531 239.5001,-161.253\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4911269088 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4911269088</title>\n",
       "<polygon fill=\"#fbb4ae\" points=\"185.5,-240 16.5,-240 16.5,-187 185.5,-187 185.5,-240\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-224.8\">BoundColumn:</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-209.8\">  Dataset: USEquityPricing</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"start\" x=\"24.5\" y=\"-194.8\">  Column: volume</text>\n",
       "</g>\n",
       "<!-- 4911269088&#45;&gt;4468037392 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4911269088-&gt;4468037392</title>\n",
       "<path d=\"M152.5,-186.8139C152.5,-186.8139 152.5,-161.2531 152.5,-161.2531\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"156.0001,-161.253 152.5,-151.2531 149.0001,-161.2531 156.0001,-161.253\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4468037392&#45;&gt;4466087416 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4468037392-&gt;4466087416</title>\n",
       "<path d=\"M194,-112.9432C194,-112.9432 194,-87.2495 194,-87.2495\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"197.5001,-87.2494 194,-77.2495 190.5001,-87.2495 197.5001,-87.2494\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Render the pipeline as a DAG\n",
    "pipeline.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the start and end dates\n",
    "start_date = pd.Timestamp('2016-01-05', tz = 'utc')\n",
    "end_date = pd.Timestamp('2016-01-05', tz = 'utc')\n",
    "\n",
    "# Run our pipeline for the given start and end dates\n",
    "pipeline_output = engine.run_pipeline(pipeline, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Universe Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values in index level 1 and save them to a list\n",
    "universe_tickers = pipeline_output.index.get_level_values(1).values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "# Create a data portal\n",
    "data_portal = DataPortal(bundle_data.asset_finder,\n",
    "                         trading_calendar = trading_calendar,\n",
    "                         first_trading_day = bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "                         equity_daily_reader = bundle_data.equity_daily_bar_reader,\n",
    "                         adjustment_reader = bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Historical Data\n",
    "\n",
    "Get the OHLC + V data for a given time period. This data will be split into individual dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_field_data(data_portal, trading_calendar, assets, start_date, end_date, field):\n",
    "    \n",
    "    # Set the given start and end dates to Timestamps. The frequency string C is used to\n",
    "    # indicate that a CustomBusinessDay DateOffset is used\n",
    "    end_dt = pd.Timestamp(end_date, tz='UTC', freq='C')\n",
    "    start_dt = pd.Timestamp(start_date, tz='UTC', freq='C')\n",
    "\n",
    "    # Get the locations of the start and end dates\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    # return the historical data for the given window\n",
    "    return data_portal.get_history_window(assets=assets, end_dt=end_dt, bar_count=end_loc - start_loc,\n",
    "                                          frequency='1d',\n",
    "                                          field=field,\n",
    "                                          data_frequency='daily')\n",
    "\n",
    "# The window of data to obtain\n",
    "start_date = '2015-01-05'\n",
    "end_data = '2016-01-05'\n",
    "\n",
    "# Get the open data\n",
    "open_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                          start_date, end_date, 'open')\n",
    "\n",
    "# Get the high data\n",
    "high_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'high')\n",
    "\n",
    "# Get the low data\n",
    "low_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                         start_date, end_date, 'low')\n",
    "\n",
    "# Get the closing data\n",
    "close_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'close') \n",
    "\n",
    "# Get the volume data\n",
    "volume_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                            start_date, end_date, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine OHLC dataframes into singular dataframe\n",
    "Here we combine the four individual dataframes representing OHLC + V data into one historical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create dataframe and append blank row\n",
    "historical_dfs = pd.DataFrame(columns=universe_tickers)\n",
    "historical_dfs = historical_dfs.append(pd.Series([np.nan]), ignore_index=True)\n",
    "\n",
    "# Loop through each universe ticker and create a combined dataframe for that ticker\n",
    "for ticker in universe_tickers:\n",
    "    # Get individual series representing the OHLCV data\n",
    "    open_series = open_data[ticker]\n",
    "    high_series = high_data[ticker]\n",
    "    low_series = low_data[ticker]\n",
    "    close_series = close_data[ticker]\n",
    "    volume_series = volume_data[ticker]\n",
    "    \n",
    "    # Combine these series into 1 dataframe\n",
    "    columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "    df = pd.concat([open_series,high_series, low_series, close_series, volume_series], axis=1)\n",
    "    df.columns = columns    \n",
    "    \n",
    "    # Save this dataframe to historical_dfs\n",
    "    historical_dfs[ticker] = pd.Series([df])\n",
    "    \n",
    "    \n",
    "# Change the columns to be more human readable\n",
    "columns = helper.beautify_tickers(universe_tickers)\n",
    "historical_dfs.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypf.instrument import DataframeInstrument\n",
    "from pypf.chart import PFChart\n",
    "\n",
    "# Set up dataframe instrument\n",
    "df = historical_dfs['AAPL'][0]\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "df['Date'] = df.index.astype(str)\n",
    "df['Date'] = df['Date'].str.slice(0,10)\n",
    "df['Volume'] = df['Volume'].astype(int)\n",
    "dfi = DataframeInstrument('AAPL', dataframe=df)\n",
    "\n",
    "# Create pf chart\n",
    "chart = PFChart(dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart.create_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  AAPL  (2016-01-05 o: 105.75 h: 105.85 l: 102.41 c: 102.71)\n",
      "  1.00% box, 3 box reversal, hl method\n",
      "  signal: sell status: bear correction\n",
      "\n",
      " 133.94|                                                                                                          |133.94\n",
      " 132.61|                          x                                                                               |132.61\n",
      " 131.30|                  x       x d     x       x                                                               |131.30\n",
      " 130.00|                  x d     x d     x 6     x d                                                             |130.00\n",
      " 128.71|                  x d     x d x   x d u   x d                                                             |128.71\n",
      " 127.44|                  x d x   x d u d x d u d x d                                                             |127.44\n",
      " 126.18|                  x o x d x o u d u o u d x d                                                             |126.18\n",
      " 124.93|                  x 3 u d u o 5 d u o   d x d u                                                           |124.93\n",
      " 123.69|                  x o u d u o   o u     o x d u d                                                         |123.69\n",
      " 122.47|                  x o u o 4     o       7 u d u d                                         x               |122.47\n",
      " 121.25|                  x o   o               o u d   d                                         B d             |121.25\n",
      " 120.05|                  x                     o u     o                                         x d             |120.05\n",
      " 118.87|                  x                     o       8 x                                       x d x   u       |118.87\n",
      " 117.69|              x   u                             o x d                                 x   u d x C u d     |117.69\n",
      " 116.52|              x 2 u                             o x d x                               x d u d u d u d     |116.52\n",
      " 115.37|              u d u                             o u d u d                 x   u       x d u o u d u d     |115.37\n",
      " 114.23|              u d                               o u d u d                 x d u d     x d   o u d   o     |114.23\n",
      " 113.10|              u                                 o u d u d     x       x   u d u d     x     o u     o     |113.10\n",
      " 111.98|          x   u                                 o   o u d     u 9 x   u d u d   d     x     o       o     |111.98\n",
      " 110.87|  x   u   x d u                                     o u o     u d u d u d u     o u   u             o     |110.87\n",
      " 109.77|  x d u d x d u                                     o   o u   u d u d u d       o u A u             o     |109.77\n",
      " 108.68|  x d u d u d u                                         o u d u d u d           o u d u             o     |108.68\n",
      " 107.61|  x d   d u d                                           o u d u d               o   d               o     |107.61\n",
      " 106.54|  x     o u                                             o u d u                                     o     |106.54\n",
      " 105.49|  x     o u                                             o u d                                       o u   |<< 102.71\n",
      " 104.44|        o                                               o u                                         1 u   |104.44\n",
      " 103.41|                                                        o u                                         o u   |103.41\n",
      " 102.38|                                                        o u                                         o     |102.38\n",
      " 101.37|                                                        o u                                               |101.37\n",
      " 100.37|                                                        o u                                               |100.37\n",
      "  99.37|                                                        o u                                               |99.37\n",
      "  98.39|                                                        o u                                               |98.39\n",
      "  97.42|                                                        o u                                               |97.42\n",
      "  96.45|                                                        o u                                               |96.45\n",
      "  95.50|                                                        o u                                               |95.50\n",
      "  94.55|                                                        o u                                               |94.55\n",
      "  93.61|                                                        o u                                               |93.61\n",
      "  92.69|                                                        o u                                               |92.69\n",
      "  91.77|                                                        o                                                 |91.77\n",
      "  90.86|                                                                                                          |90.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chart.chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(pypf)\n",
    "importlib.reload(pypf.instrument)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:julie-stav-ws]",
   "language": "python",
   "name": "conda-env-julie-stav-ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
