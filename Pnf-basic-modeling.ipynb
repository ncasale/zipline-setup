{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Empty Pipeline with Screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resources\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors.basic import SimpleMovingAverage\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "# Create a screen for our Pipeline\n",
    "mean_close_10 = SimpleMovingAverage(\n",
    "    inputs=[USEquityPricing.close],\n",
    "    window_length=10\n",
    ")\n",
    "\n",
    "universe = mean_close_10 > 10\n",
    "\n",
    "# Create an empty Pipeline with the given screen\n",
    "pipeline = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zipline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from zipline.utils.calendars import get_calendar\n",
    "from zipline.data import bundles\n",
    "\n",
    "# Name of bundle\n",
    "EOD_BUNDLE_NAME = 'quantopian-quandl'\n",
    "\n",
    "# Load the data bundle\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Setup the engine to look at the top 500 stocks who have had the highest rolling Average Dollar Volume\n",
    "# over a 120-day window -- This is arbitrary and we can use this parameter to refine which stocks we\n",
    "# want in our universe\n",
    "universe = mean_close_10.top(500) \n",
    "\n",
    "# Select the trading calendar that will be used as a reference when slicing the data\n",
    "trading_calendar = get_calendar('NYSE') \n",
    "\n",
    "# Load the bundle we configured in the previous step into the engine\n",
    "bundle_data = bundles.load(EOD_BUNDLE_NAME)\n",
    "\n",
    "# Create the engine -- the details of this function are in the utils.py file\n",
    "engine = helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the start and end dates\n",
    "start_date = pd.Timestamp('2017-01-05', tz = 'utc')\n",
    "end_date = pd.Timestamp('2017-01-05', tz = 'utc')\n",
    "\n",
    "# Run our pipeline for the given start and end dates\n",
    "pipeline_output = engine.run_pipeline(pipeline, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Universe Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values in index level 1 and save them to a list\n",
    "universe_tickers = pipeline_output.index.get_level_values(1).values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "# Create a data portal\n",
    "data_portal = DataPortal(bundle_data.asset_finder,\n",
    "                         trading_calendar = trading_calendar,\n",
    "                         first_trading_day = bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "                         equity_daily_reader = bundle_data.equity_daily_bar_reader,\n",
    "                         adjustment_reader = bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Historical Data\n",
    "\n",
    "Get the OHLC + V data for a given time period. This data will be split into individual dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_field_data(data_portal, trading_calendar, assets, start_date, end_date, field):\n",
    "    \n",
    "    # Set the given start and end dates to Timestamps. The frequency string C is used to\n",
    "    # indicate that a CustomBusinessDay DateOffset is used\n",
    "    end_dt = pd.Timestamp(end_date, tz='UTC', freq='C')\n",
    "    start_dt = pd.Timestamp(start_date, tz='UTC', freq='C')\n",
    "\n",
    "    # Get the locations of the start and end dates\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    # return the historical data for the given window\n",
    "    return data_portal.get_history_window(assets=assets, end_dt=end_dt, bar_count=end_loc - start_loc,\n",
    "                                          frequency='1d',\n",
    "                                          field=field,\n",
    "                                          data_frequency='daily')\n",
    "\n",
    "# The window of data to obtain\n",
    "start_date = '2012-01-05'\n",
    "end_date = '2017-01-05'\n",
    "\n",
    "# Get the open data\n",
    "open_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                          start_date, end_date, 'open')\n",
    "\n",
    "# Get the high data\n",
    "high_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'high')\n",
    "\n",
    "# Get the low data\n",
    "low_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                         start_date, end_date, 'low')\n",
    "\n",
    "# Get the closing data\n",
    "close_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                              start_date, end_date, 'close') \n",
    "\n",
    "# Get the volume data\n",
    "volume_data = get_field_data(data_portal, trading_calendar, universe_tickers,\n",
    "                            start_date, end_date, 'volume')\n",
    "\n",
    "from pypf.instrument import DataframeInstrument\n",
    "from pypf.chart import PFChart\n",
    "\n",
    "def generate_pf_chart(ticker, historical_dfs):\n",
    "    ''' \n",
    "        This function will create a p&f chart for the given ticker using historical data\n",
    "        \n",
    "        @param ticker: (str) ticker of asset to create P&F chart for\n",
    "        @param historical_dfs: (pd.DataFrame) DataFrame holding historical ticker data\n",
    "        \n",
    "        return: PFChart object from which P&F chart/data can be extracted\n",
    "    \n",
    "    '''\n",
    "    # Set up dataframe instrument\n",
    "    try:\n",
    "        df = historical_dfs[ticker][0]\n",
    "    except:\n",
    "        raise ValueError('Ticker passed does not exist in historical dataset')\n",
    "\n",
    "    # Format date and volume values\n",
    "    df['Date'] = df.index.astype(str)\n",
    "    df['Date'] = df['Date'].str.slice(0,10)\n",
    "    df['Volume'] = df['Volume'].astype(int)\n",
    "\n",
    "    # Tes\n",
    "    dfi = DataframeInstrument(ticker, dataframe=df)\n",
    "\n",
    "    # Create pf chart\n",
    "    chart = PFChart(dfi, duration=5)\n",
    "    chart.create_chart()\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine OHLC dataframes into singular dataframe\n",
    "Here we combine the four individual dataframes representing OHLC + V data into one historical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create dataframe and append blank row\n",
    "historical_dfs = pd.DataFrame(columns=universe_tickers)\n",
    "historical_dfs = historical_dfs.append(pd.Series([np.nan]), ignore_index=True)\n",
    "\n",
    "# Loop through each universe ticker and create a combined dataframe for that ticker\n",
    "for ticker in universe_tickers:\n",
    "    # Get individual series representing the OHLCV data\n",
    "    open_series = open_data[ticker]\n",
    "    high_series = high_data[ticker]\n",
    "    low_series = low_data[ticker]\n",
    "    close_series = close_data[ticker]\n",
    "    volume_series = volume_data[ticker]\n",
    "    \n",
    "    # Combine these series into 1 dataframe\n",
    "    columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = pd.concat([open_series,high_series, low_series, close_series, volume_series], axis=1)\n",
    "    df.columns = columns    \n",
    "    \n",
    "    # Save this dataframe to historical_dfs\n",
    "    historical_dfs[ticker] = pd.Series([df])\n",
    "    \n",
    "    \n",
    "# Change the columns to be more human readable\n",
    "columns = helper.beautify_tickers(universe_tickers)\n",
    "historical_dfs.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format P&F Chart Data For Analysis\n",
    "Create a new DataFrame to hold the P&F chart data to be used for model training datasets. \n",
    "Columns '50 Day Moving Average of Volume' and 'Ratio of Volume to The 50 Day Moving Average' are generated (Does not apply to first 50 datapoints). Categorical columns are refactored to be nomial integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(pf_chart):\n",
    "    # Import security data as a dataframe\n",
    "    pf_chart_data = pd.DataFrame.from_dict(pf_chart.chart_meta_data)\n",
    "    pf_chart_data = pf_chart_data.transpose().reset_index(drop=True)\n",
    "\n",
    "    # Create a 50 day moving average of the volume and a ratio between the volume and the 50 day moving average\n",
    "    pf_chart_data['50ma'] = pd.Series.rolling(pf_chart_data['volume'],50, min_periods=50).mean().round()\n",
    "    pf_chart_data['volume_ratio'] = (pf_chart_data['volume'] / pf_chart_data['50ma'])\n",
    "    # Reformat categorical columns to be numeric (cant decide if these should be numbered by index or polarity ie: buy is 1, sell is -1, none is 0)\n",
    "    pf_chart_data['action'] = pf_chart_data['action'].map({'none': 0, 'x': 1, 'reverse x->o': 2, 'o': 3, 'reverse o->x': 4})\n",
    "    pf_chart_data['direction'] = pf_chart_data['direction'].map({'o': 0, 'x':1})\n",
    "    pf_chart_data['signal'] = pf_chart_data['signal'].map({'sell': 0, 'buy':1}) # We may want to refactor this so none = NaN\n",
    "    \n",
    "    return pf_chart_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classification and Regression With Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "\n",
    "def CART_Output(title,df,X,Y,df_names,test_size,random_state,max_depth,min_samples_leaf):\n",
    "    #define training and test samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = test_size, random_state = random_state)\n",
    "    X_train = X_train.astype(int)\n",
    "    y_train = y_train.astype(int)\n",
    "    X_test = X_test.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "\n",
    "    #predict using Gini results\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = random_state,\n",
    "                                   max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    y_pred = clf_gini.predict(X_test)\n",
    "\n",
    "    #redefine arrays as integer (otherwise error message results from accuracy calculation)\n",
    "    y_test = y_test.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    print (\"Values for factors for Gini -\",title,\":\")\n",
    "    print('')\n",
    "\n",
    "    def measure_performance(X,y,clf_gini, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "        y_pred=clf_gini.predict(X)   \n",
    "        if show_accuracy:\n",
    "            print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "        if show_classification_report:\n",
    "            print (\"Classification report\")\n",
    "            print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "\n",
    "        if show_confusion_matrix:\n",
    "            print (\"Confusion matrix\")\n",
    "            print (metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "\n",
    "    output = measure_performance(X_train,y_train,clf_gini, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True)\n",
    "    feature_names=df_names\n",
    "    with open(\"cart-models/\"+title+\"_\"+str(test_size)+\"_\"+str(random_state)+\"_\"+str(max_depth)+\"_\"+str(min_samples_leaf)+\".txt\", \"w\") as f:\n",
    "        f = tree.export_graphviz(clf_gini, feature_names=df_names, out_file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classification and Regression (Dynamic Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "def CART_Test(title,df,X,Y,df_names,test_size,random_state,max_depth,min_samples_leaf):\n",
    "\n",
    "    #define training and test samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = test_size, random_state = random_state)\n",
    "    X_train = X_train.astype(int)\n",
    "    y_train = y_train.astype(int)\n",
    "    X_test = X_test.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "\n",
    "    #predict using Gini results\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = random_state,\n",
    "                                   max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    y_pred = clf_gini.predict(X_test)\n",
    "\n",
    "    #redefine arrays as integer (otherwise error message results from accuracy calculation)\n",
    "    y_test = y_test.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "\n",
    "    def measure_performance(X,y,clf_gini, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "        y_pred=clf_gini.predict(X)   \n",
    "        if show_accuracy:\n",
    "            accuracy = metrics.accuracy_score(y,y_pred)\n",
    "        if show_classification_report:\n",
    "            classification_report = metrics.classification_report(y,y_pred)\n",
    "        if show_confusion_matrix:\n",
    "            confusion_matrix = metrics.confusion_matrix(y,y_pred)\n",
    "        return accuracy, classification_report, confusion_matrix\n",
    "    accuracy, classification_report, confusion_matrix = measure_performance(X_train,y_train,clf_gini, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True)\n",
    "    report_entry = {\n",
    "        'ticker': '',\n",
    "        'test_size': test_size,\n",
    "        'random_state': random_state, \n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': classification_report, \n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }\n",
    "    return report_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Set the tickers and parameter values to be tested \n",
    "ticker_set = ['AAPL', 'MMM', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GS', 'HD' , 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'UTX', 'UNH', 'VZ', 'V', 'WMT', 'WBA']\n",
    "test_size_set = [.20,.25,.30] # Percent of the data that is used as training data (Range = 0:1) \n",
    "random_state_set = [0,100] # Percent of the data that is randomized in the training/testing data (Range = 0:100)\n",
    "max_depth_set = [3,4,5] # Max number of layers in the model (Range = 1:inf)\n",
    "min_samples_leaf_set = [5,15,30] # Minimum number of samples in a group to split on (Range = 1:inf)\n",
    " \n",
    "accuracy_report = pd.DataFrame(columns = ['ticker', 'test_size', 'random_state', 'max_depth', 'min_samples_leaf', 'accuracy', 'classification_report', 'confusion_matrix'])\n",
    "current_ticker = ''\n",
    "\n",
    "# Test all combinations of the given objects\n",
    "for ticker, test_size, random_state, max_depth, min_samples_leaf in itertools.product(ticker_set, test_size_set, random_state_set, max_depth_set, min_samples_leaf_set):\n",
    "    if current_ticker != ticker:\n",
    "        current_ticker = ticker\n",
    "        clear_output()\n",
    "        print ('On Ticker: ' + ticker)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Set input variables to test\n",
    "    \n",
    "    # Numeric values or column names of independent varibles\n",
    "    input_cols = [1,5,6,8,9,10,15,16,17]\n",
    "    # Numeric value or column name of the dependent variable\n",
    "    output_col = 13\n",
    "    # Title of the chart\n",
    "    title = 'PnF of ' + ticker \n",
    "\n",
    "    # Create a p&f chart for the given ticker using historical data and print the result\n",
    "    pf_chart = generate_pf_chart(ticker, historical_dfs)\n",
    "    # Format P&F Chart Data For Analysis\n",
    "    pf_chart_data = format_data(pf_chart)\n",
    "    # Set the DataFrame to test\n",
    "    df = pf_chart_data\n",
    "    \n",
    "    # Clean dataset of rows that contain 'nan'\n",
    "    df.dropna(inplace = True, axis = 'rows')\n",
    "    \n",
    "    #Set the range of the test ()\n",
    "    X = df.values[:len(df)-1,(input_cols)]\n",
    "    Y = df.values[1:len(df),output_col]\n",
    "\n",
    "\n",
    "    # Run the CART model generator\n",
    "    df_names = list(df.columns.values[input_cols])\n",
    "    report_entry = CART_Test(title,df,X,Y,df_names,test_size,random_state,max_depth,min_samples_leaf)\n",
    "    report_entry['ticker'] = ticker\n",
    "    accuracy_report = accuracy_report.append(report_entry, ignore_index=True)\n",
    "\n",
    "# Reorder accuracy report descending by accuracy\n",
    "accuracy_report = accuracy_report.sort_values(by='accuracy',ascending=False).reset_index(drop=True)\n",
    "clear_output()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.950216</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[189, 20], [26, 689]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PG</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946682</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[251, 14], [31, 548]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WMT</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946203</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[381, 32], [19, 516]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931280</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[302, 45], [13, 484]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MMM</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930095</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[175, 42], [17, 610]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIS</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929534</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[188, 63], [5, 709]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GS</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.927725</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[240, 24], [37, 543]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CVX</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[312, 12], [50, 470]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MCD</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[328, 41], [24, 437]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>KO</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.905213</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[340, 34], [46, 424]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>PFE</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.899482</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[281, 62], [35, 587]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>IBM</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.894301</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[485, 53], [49, 378]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>UTX</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.889810</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[182, 26], [67, 569]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>HD</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888398</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[189, 62], [39, 615]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NKE</td>\n",
       "      <td>0.25</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[199, 47], [53, 589]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>JPM</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.873575</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[142, 97], [25, 701]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>V</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.869668</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[78, 101], [9, 656]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>VZ</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.869668</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[245, 63], [47, 489]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>UNH</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.863212</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[165, 114], [18, 668]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>INTC</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[276, 87], [63, 539]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>WBA</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.842417</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[215, 115], [18, 496]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>BA</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[209, 61], [87, 487]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>CAT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.818785</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[391, 52], [112, 350]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[232, 110], [44, 458]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>MRK</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.814545</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[212, 85], [68, 460]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.797393</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[134, 165], [6, 539]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.764767</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>[[126, 219], [8, 612]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker  test_size random_state max_depth min_samples_leaf  accuracy  \\\n",
       "0       JNJ       0.20          100         5                5  0.950216   \n",
       "3        PG       0.30            0         5                5  0.946682   \n",
       "4       WMT       0.20            0         5                5  0.946203   \n",
       "14      XOM       0.30            0         5                5  0.931280   \n",
       "16      MMM       0.30            0         5                5  0.930095   \n",
       "19      DIS       0.20          100         5                5  0.929534   \n",
       "25       GS       0.30            0         5                5  0.927725   \n",
       "27      CVX       0.30          100         5                5  0.926540   \n",
       "36      MCD       0.30            0         5                5  0.921687   \n",
       "74       KO       0.30            0         5                5  0.905213   \n",
       "94      PFE       0.20          100         5                5  0.899482   \n",
       "117     IBM       0.20          100         5                5  0.894301   \n",
       "142     UTX       0.30          100         5                5  0.889810   \n",
       "147      HD       0.25          100         5                5  0.888398   \n",
       "151     NKE       0.25          100         5               15  0.887387   \n",
       "234     JPM       0.20            0         5                5  0.873575   \n",
       "260       V       0.30            0         5                5  0.869668   \n",
       "262      VZ       0.30          100         5                5  0.869668   \n",
       "321     UNH       0.20            0         5                5  0.863212   \n",
       "484    INTC       0.20            0         5                5  0.844560   \n",
       "508     WBA       0.30            0         5                5  0.842417   \n",
       "713      BA       0.30            0         5                5  0.824645   \n",
       "741     CAT       0.25            0         5                5  0.818785   \n",
       "759    AAPL       0.30          100         5                5  0.817536   \n",
       "776     MRK       0.30            0         5                5  0.814545   \n",
       "927    CSCO       0.30            0         5                5  0.797393   \n",
       "1145   MSFT       0.20            0         5                5  0.764767   \n",
       "\n",
       "                                  classification_report  \\\n",
       "0                  precision    recall  f1-score   s...   \n",
       "3                  precision    recall  f1-score   s...   \n",
       "4                  precision    recall  f1-score   s...   \n",
       "14                 precision    recall  f1-score   s...   \n",
       "16                 precision    recall  f1-score   s...   \n",
       "19                 precision    recall  f1-score   s...   \n",
       "25                 precision    recall  f1-score   s...   \n",
       "27                 precision    recall  f1-score   s...   \n",
       "36                 precision    recall  f1-score   s...   \n",
       "74                 precision    recall  f1-score   s...   \n",
       "94                 precision    recall  f1-score   s...   \n",
       "117                precision    recall  f1-score   s...   \n",
       "142                precision    recall  f1-score   s...   \n",
       "147                precision    recall  f1-score   s...   \n",
       "151                precision    recall  f1-score   s...   \n",
       "234                precision    recall  f1-score   s...   \n",
       "260                precision    recall  f1-score   s...   \n",
       "262                precision    recall  f1-score   s...   \n",
       "321                precision    recall  f1-score   s...   \n",
       "484                precision    recall  f1-score   s...   \n",
       "508                precision    recall  f1-score   s...   \n",
       "713                precision    recall  f1-score   s...   \n",
       "741                precision    recall  f1-score   s...   \n",
       "759                precision    recall  f1-score   s...   \n",
       "776                precision    recall  f1-score   s...   \n",
       "927                precision    recall  f1-score   s...   \n",
       "1145               precision    recall  f1-score   s...   \n",
       "\n",
       "             confusion_matrix  \n",
       "0      [[189, 20], [26, 689]]  \n",
       "3      [[251, 14], [31, 548]]  \n",
       "4      [[381, 32], [19, 516]]  \n",
       "14     [[302, 45], [13, 484]]  \n",
       "16     [[175, 42], [17, 610]]  \n",
       "19      [[188, 63], [5, 709]]  \n",
       "25     [[240, 24], [37, 543]]  \n",
       "27     [[312, 12], [50, 470]]  \n",
       "36     [[328, 41], [24, 437]]  \n",
       "74     [[340, 34], [46, 424]]  \n",
       "94     [[281, 62], [35, 587]]  \n",
       "117    [[485, 53], [49, 378]]  \n",
       "142    [[182, 26], [67, 569]]  \n",
       "147    [[189, 62], [39, 615]]  \n",
       "151    [[199, 47], [53, 589]]  \n",
       "234    [[142, 97], [25, 701]]  \n",
       "260     [[78, 101], [9, 656]]  \n",
       "262    [[245, 63], [47, 489]]  \n",
       "321   [[165, 114], [18, 668]]  \n",
       "484    [[276, 87], [63, 539]]  \n",
       "508   [[215, 115], [18, 496]]  \n",
       "713    [[209, 61], [87, 487]]  \n",
       "741   [[391, 52], [112, 350]]  \n",
       "759   [[232, 110], [44, 458]]  \n",
       "776    [[212, 85], [68, 460]]  \n",
       "927    [[134, 165], [6, 539]]  \n",
       "1145   [[126, 219], [8, 612]]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_report = accuracy_report.drop_duplicates(subset = 'ticker')\n",
    "for index, row in ticker_report.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    test_size = row['test_size']\n",
    "    max_depth = row['max_depth']\n",
    "    random_state = row['random_state']\n",
    "    min_samples_leaf = row['min_samples_leaf']\n",
    "    min_samples_leaf = row['min_samples_leaf']\n",
    "    \n",
    "    # Recreate the analysis DataFrame using the best performer\n",
    "    pf_chart = generate_pf_chart(ticker, historical_dfs)\n",
    "    pf_chart_data = format_data(pf_chart)\n",
    "    df = pf_chart_data\n",
    "    df.dropna(inplace = True, axis = 'rows')\n",
    "    X = df.values[:len(df)-1,(input_cols)]\n",
    "    Y = df.values[1:len(df),output_col]\n",
    "\n",
    "    # Run the CART model generator\n",
    "    title = 'PnF of ' + ticker \n",
    "    df_names = list(df.columns.values[input_cols])\n",
    "\n",
    "    CART_Output(title,df,X,Y,df_names,test_size,random_state,max_depth,min_samples_leaf) \n",
    "clear_output()\n",
    "ticker_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 6 ML models to compare accuracies\n",
    "Using the pf_chart_data DataFrame's independent variables, different non-linear functions can be quickly tested to gauge general accuracy in predicting the dependent variable, buy_sell_col. The box and whisker plots provided in the output graph the different results as well as their accuracy spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "# TODO: Add confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zipline]",
   "language": "python",
   "name": "conda-env-zipline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
